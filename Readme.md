# ğŸ”¥ DeltaForge

## DeltaForge â€“ End-to-End Databricks Ã— DBT Lakehouse Data Engineering Project

DeltaForge is a production-grade data engineering project built using Databricks, Apache PySpark, Delta Lake, and DBT.  
It demonstrates an end-to-end lakehouse architecture using the medallion pattern (Bronze, Silver, Gold).

---

## ğŸ§  Architecture Overview

- **Bronze Layer** â€“ Raw data ingestion (Delta Lake)
- **Silver Layer** â€“ Cleaned & validated data (PySpark)
- **Gold Layer** â€“ Analytics-ready marts (PySpark)
- **Business View** - Business Use Cases Solved (DBT)

---

## ğŸš€ Tech Stack

- Databricks
- Apache Spark (PySpark)
- Delta Lake
- DBT
- SQL
- Python

---

## ğŸ“‚ Project Structure

- `databricks/` â†’ PySpark ETL notebooks
- `dbt/` â†’ SQL-based transformations
- `workflows/` â†’ Databricks job orchestration
- `utils/` â†’ Data quality utilities

---

## â–¶ï¸ How to Run

1. Upload notebooks to Databricks.
2. Configure Delta tables
3. Make a BronzeIngestion Pipeline which is linked to the Bronze Stage notebook.
4. Make a SilverIngestion ETL Pipeline which will contain the Silver Stage notebook.
5. Run the Gold Notebooks.
4. Execute DBT models:
   ```bash
   dbt run